{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vpHuY9lSGj2j"
      },
      "source": [
        "# üéì Aula: Prevendo a evas√£o escolar com Deep Learning"
      ],
      "id": "vpHuY9lSGj2j"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AssVkTFuGj2k"
      },
      "source": [
        "## 1. Contextualizando o Problema (O \"Porqu√™\")\n",
        "\n",
        "A evas√£o escolar e universit√°ria √© um dos problemas mais cr√≠ticos enfrentados pelas institui√ß√µes de ensino hoje. O impacto n√£o √© apenas financeiro para a institui√ß√£o, que perde receita e investimento, mas √©, acima de tudo, um impacto social e individual.\n",
        "\n",
        "Um aluno que evade pode enfrentar:\n",
        "* Menores oportunidades de carreira.\n",
        "* Dificuldade em quitar d√≠vidas estudantis (se aplic√°vel).\n",
        "* Um ciclo de desengajamento acad√™mico.\n",
        "\n",
        "**O Desafio:** A interven√ß√£o √© mais eficaz quando √© precoce. O problema √© que, tradicionalmente, as interven√ß√µes s√£o reativas (ocorrem *depois* que o aluno j√° demonstrou sinais claros de evas√£o, como faltas ou notas muito baixas).\n",
        "\n",
        "**A Oportunidade (Data Science):** E se pud√©ssemos usar os dados para identificar *proativamente* os alunos em risco de evas√£o, *antes* que eles cheguem a um ponto cr√≠tico?"
      ],
      "id": "AssVkTFuGj2k"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uc2f4KoAGj2l"
      },
      "source": [
        "## 2. O Problema de Data Science (O \"O Qu√™\")\n",
        "\n",
        "O problema de neg√≥cio (\"reduzir a evas√£o\") √© traduzido para um problema de Data Science como:\n",
        "\n",
        "> **\"Dado um conjunto de atributos de um aluno (demogr√°ficos, socioecon√¥micos e acad√™micos), podemos construir um modelo para prever se ele ir√° evadir ou se formar?\"**\n",
        "\n",
        "Este √© um cl√°ssico problema de **Classifica√ß√£o Bin√°ria**. O nosso \"alvo\" (target) √© uma vari√°vel categ√≥rica com duas sa√≠das:\n",
        "1.  **Dropout** (Evas√£o)\n",
        "2.  **Graduate** (Formado / Sucesso)"
      ],
      "id": "Uc2f4KoAGj2l"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Z2flthAGj2l"
      },
      "source": [
        "### 3. Estudo de Caso:\n",
        "\n",
        "Para explorar como resolver o problema de predi√ß√£o de evas√£o acad√™mica, utilizaremos como refer√™ncia o estudo conduzido por **Martins et al. (2021)**, apresentado no *World Conference on Information Systems and Technologies*, intitulado *Early Prediction of Student‚Äôs Performance in Higher Education: A Case Study* (MARTINS et al., 2021).\n",
        "\n",
        "Neste trabalho, os autores analisam o desempenho de estudantes do ensino superior e prop√µem um modelo preditivo capaz de antecipar casos de evas√£o e sucesso acad√™mico com base em dados hist√≥ricos e socioecon√¥micos. O estudo se baseia em um conjunto de dados disponibilizado publicamente na **UCI Machine Learning Repository**, intitulado *Predict Students‚Äô Dropout and Academic Success*, originalmente desenvolvido por **Valentim Realinho, Jorge Machado, Lu√≠s Baptista e M√≥nica V. Martins (2021)**.  \n",
        "\n",
        "üîó **Link do dataset:** [https://archive.ics.uci.edu/dataset/697/predict+students+dropout+and+academic+success](https://archive.ics.uci.edu/dataset/697/predict+students+dropout+and+academic+success)\n",
        "\n",
        "üîó **Link no nosso Github:** [Link do dataset - Github](https://raw.githubusercontent.com/prof-danny-idp/deep-learning/refs/heads/main/modulo_01_fundamentos/dataset/student_dropout.csv)\n",
        "\n",
        "O dataset √© robusto e cont√©m dezenas de vari√°veis, incluindo:\n",
        "- **Dados demogr√°ficos:** idade, g√™nero, nacionalidade.  \n",
        "- **Dados socioecon√¥micos:** situa√ß√£o de bolsa, ocupa√ß√£o dos pais, renda familiar.  \n",
        "- **Hist√≥rico acad√™mico:** n√∫mero de unidades de cr√©dito cursadas, taxas de aprova√ß√£o, notas m√©dias, status de matr√≠cula em semestres anteriores.  \n",
        "\n",
        "Essas informa√ß√µes permitem construir modelos de **classifica√ß√£o bin√°ria**, cujo objetivo √© prever se um aluno est√° mais propenso a **evadir (dropout)** ou **se formar (graduate)**.\n",
        "\n",
        "Estudos posteriores, como o de **Rani, Pachigolla e Kumar (2025)**, refor√ßam a import√¢ncia de um bom pr√©-processamento dos dados educacionais. Esses autores prop√µem uma etapa de **agrupamento (clustering)** para redu√ß√£o de dimensionalidade e melhoria da robustez dos modelos de classifica√ß√£o aplicados √† previs√£o de evas√£o estudantil ‚Äî uma abordagem complementar que pode potencializar o desempenho de modelos de **Deep Learning**, como redes neurais densas.\n",
        "\n",
        "Dessa forma, o projeto *Predict Students‚Äô Dropout and Academic Success* e seus estudos correlatos representam uma base s√≥lida para compreender tanto os **desafios reais** do problema de evas√£o quanto as **t√©cnicas modernas** aplicadas √† predi√ß√£o de sucesso acad√™mico em ambientes educacionais.\n",
        "\n",
        "---\n",
        "\n",
        "**Refer√™ncias:**\n",
        "\n",
        "- MARTINS, M√≥nica V. et al. *Early prediction of student‚Äôs performance in higher education: A case study.*  \n",
        "  In: *World Conference on Information Systems and Technologies.* Cham: Springer International Publishing, 2021. p. 166‚Äì175.  \n",
        "\n",
        "- RANI, Nisha; PACHIGOLLA, Venkata Suresh; KUMAR, Akshay. *Clustering based pre-processing for feature reduction and robust student dropout classification.*  \n",
        "  *International Journal of Information Technology*, p. 1‚Äì13, 2025.  \n",
        "\n",
        "- Valentim Realinho, Jorge Machado, Lu√≠s Baptista, & M√≥nica V. Martins. (2021).  \n",
        "  *Predict students' dropout and academic success* [Data set]. UCI Machine Learning Repository.  \n",
        "  Dispon√≠vel em: [https://archive.ics.uci.edu/dataset/697/predict+students+dropout+and+academic+success](https://archive.ics.uci.edu/dataset/697/predict+students+dropout+and+academic+success)\n",
        "\n"
      ],
      "id": "1Z2flthAGj2l"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Construindo a rede neural"
      ],
      "metadata": {
        "id": "rK4EjNneKyeR"
      },
      "id": "rK4EjNneKyeR"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dcu7dHyuGj2l"
      },
      "outputs": [],
      "source": [
        "# C√©lula de C√≥digo 1: Importa√ß√£o e Explora√ß√£o Inicial\n",
        "\n",
        "SEED = 1895 # Vai pra cima deles meng√£o\n",
        "\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n"
      ],
      "id": "Dcu7dHyuGj2l"
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "o0HCHMKPMAVv"
      },
      "id": "o0HCHMKPMAVv"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yws9-N91Gj2m"
      },
      "outputs": [],
      "source": [
        "#  Pr√©-processamento dos dados\n",
        "\n",
        "\n",
        "# Normaliza√ß√£o dos dados\n",
        "\n",
        "\n",
        "# Retirar as vari√°veis categ√≥ricas\n",
        "\n",
        "\n",
        "\n",
        "# Retirar agora o Target == Enrolled\n",
        "\n",
        "\n",
        "\n",
        "# Separar em X e Y\n",
        "\n"
      ],
      "id": "yws9-N91Gj2m"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üìè Dica t√©cnica: Como Normalizar e Padronizar seus Dados (X)\n",
        "\n",
        "A normaliza√ß√£o (ou padroniza√ß√£o) √© um passo crucial de pr√©-processamento. Muitos algoritmos de Machine Learning (como Redes Neurais, SVMs, KNN e regress√µes com regulariza√ß√£o) funcionam melhor ou convergem mais r√°pido quando os dados de entrada (features) est√£o na mesma escala.\n",
        "\n",
        "Abaixo, explicamos o processo correto para evitar **Data Leakage** e apresentamos as duas t√©cnicas mais comuns do Scikit-learn: **StandardScaler** e **MinMaxScaler**.\n",
        "\n",
        "---\n",
        "\n",
        "### ‚ö†Ô∏è A Regra de Ouro: Evitando Data Leakage\n",
        "\n",
        "O erro mais comum √© normalizar o `X` *antes* de dividi-lo em treino e teste.\n",
        "\n",
        "**O correto √©:**\n",
        "1.  **Dividir** os dados primeiro (`train_test_split`).\n",
        "2.  **Aprender** (usar `.fit()`) os par√¢metros da normaliza√ß√£o (m√©dia, desvio padr√£o, min, max) **APENAS** nos dados de **treino** (`X_train`).\n",
        "3.  **Aplicar** (usar `.transform()`) essa transforma√ß√£o aprendida nos dados de **treino** (`X_train`) e **teste** (`X_test`).\n",
        "\n",
        "Isso simula o mundo real, onde seu modelo n√£o pode \"ver\" os dados de teste antes da hora."
      ],
      "metadata": {
        "id": "BWjrmq3yBHrC"
      },
      "id": "BWjrmq3yBHrC"
    },
    {
      "cell_type": "code",
      "source": [
        "## Separando meus dados - Abordagem diferente\n",
        "\n"
      ],
      "metadata": {
        "id": "A5qKU-UNBAd_"
      },
      "id": "A5qKU-UNBAd_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Padroniza√ß√£o (StandardScaler)\n",
        "\n",
        "Esta √© a t√©cnica mais comum. Ela transforma os dados para que tenham:\n",
        "* **M√©dia = 0**\n",
        "* **Desvio Padr√£o = 1**\n",
        "\n",
        "√â muito robusta e funciona bem com a maioria dos algoritmos. √â menos sens√≠vel a *outliers* do que o MinMaxScaler.\n",
        "\n",
        "**üìñ Documenta√ß√£o:** [sklearn.preprocessing.StandardScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html)\n",
        "\n",
        "**F√≥rmula Matem√°tica (Z-Score):**\n",
        "$$z = \\frac{x - \\mu}{\\sigma}$$\n",
        "Onde:\n",
        "* $x$ √© o valor original.\n",
        "* $\\mu$ (mu) √© a **m√©dia** das features (calculada no `X_train`).\n",
        "* $\\sigma$ (sigma) √© o **desvio padr√£o** das features (calculado no `X_train`).\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "cmLypfU3ByhX"
      },
      "id": "cmLypfU3ByhX"
    },
    {
      "cell_type": "markdown",
      "source": [
        "--\n",
        "\n",
        "#### 2. Normaliza√ß√£o (MinMaxScaler)\n",
        "\n",
        "Esta t√©cnica redimensiona os dados para que fiquem em um intervalo espec√≠fico, geralmente **[0, 1]**.\n",
        "\n",
        "√â √∫til quando voc√™ sabe que seus dados t√™m limites definidos ou quando voc√™ precisa que os dados estejam estritamente positivos (ex: em algumas arquiteturas de redes neurais). **Cuidado:** √© muito sens√≠vel a *outliers*.\n",
        "\n",
        "**üìñ Documenta√ß√£o:** [sklearn.preprocessing.MinMaxScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html)\n",
        "\n",
        "**F√≥rmula Matem√°tica:**\n",
        "$$x_{\\text{scaled}} = \\frac{x - \\min(x)}{\\max(x) - \\min(x)}$$\n",
        "Onde:\n",
        "* $x$ √© o valor original.\n",
        "* $\\min(x)$ √© o **valor m√≠nimo** das features (calculado no `X_train`).\n",
        "* $\\max(x)$ √© o **valor m√°ximo** das features (calculado no `X_train`).\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "yTfqHB4Z66Ly"
      },
      "id": "yTfqHB4Z66Ly"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ü§î E quanto ao `Y` (a vari√°vel alvo)?\n",
        "\n",
        "* **Para Classifica√ß√£o:** **NUNCA** normalize o `Y`. Ele representa as classes (ex: 0, 1, 2) e deve permanecer como est√°.\n",
        "* **Para Regress√£o:** **√â opcional.** Se a sua vari√°vel `Y` tiver uma distribui√ß√£o muito assim√©trica (skewed) ou valores muito grandes, normaliz√°-la (geralmente com `StandardScaler` ou `log_transform`) pode ajudar o modelo a convergir.\n",
        "    * **Importante:** Se voc√™ normalizar o `y_train`, lembre-se de aplicar a transforma√ß√£o inversa (`scaler_y.inverse_transform()`) nas suas previs√µes (`y_pred`) para que elas voltem √† escala original e fa√ßam sentido no mundo real."
      ],
      "metadata": {
        "id": "VQ9VdSb36-Wc"
      },
      "id": "VQ9VdSb36-Wc"
    },
    {
      "cell_type": "code",
      "source": [
        "# Vamos normalizar com o StardScaler\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "NOcJs9q1eK8T"
      },
      "id": "NOcJs9q1eK8T",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8lx3ZW0WGj2m"
      },
      "source": [
        "## O Modelo de Deep Learning (O \"Como\")\n",
        "\n",
        "Vamos implementar uma Rede Neural Densa (tamb√©m chamada de Multi-Layer Perceptron - MLP) usando **TensorFlow** e **Keras**.\n",
        "\n",
        "* **TensorFlow:** √â a biblioteca \"motor\" do Google para computa√ß√£o num√©rica e machine learning.\n",
        "* **Keras:** √â uma API de alto n√≠vel (que roda \"em cima\" do TensorFlow) que torna a constru√ß√£o de redes neurais intuitiva.\n",
        "\n",
        "O desafio de redes neurais profundas, no entanto, √© o **overfitting** (sobreajuste)."
      ],
      "id": "8lx3ZW0WGj2m"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O0y-kCKXGj2m"
      },
      "outputs": [],
      "source": [
        "# Definindo o Modelo com TensorFlow/Keras\n",
        "\n",
        "\n",
        "# Definir otimizador e perda\n",
        "\n",
        "\n",
        "# Compilar o modelo\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "id": "O0y-kCKXGj2m"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UBz4Zr5sGj2m"
      },
      "outputs": [],
      "source": [
        "# Treinando o Modelo\n",
        "\n",
        "\n"
      ],
      "id": "UBz4Zr5sGj2m"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Finalizamos! implementar uma Rede Neural Densa (tamb√©m chamada de Multi-Layer Perceptron - MLP) usando TensorFlow e Keras.\n",
        "\n",
        "Parab√©ns por ter chegado at√© aqui.\n",
        "Nas pr√≥ximas aulas vamos aprender a criar uma Rede Neural ainda mais robusta. E, com isso, fazer estima√ß√µes ainda melhores."
      ],
      "metadata": {
        "id": "91dRfnfGRib5"
      },
      "id": "91dRfnfGRib5"
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificar com os dados de test\n",
        "\n"
      ],
      "metadata": {
        "id": "13Wwo9TLiDa2"
      },
      "id": "13Wwo9TLiDa2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dica extra - Estima√ß√£o do pregui√ßoso"
      ],
      "metadata": {
        "id": "7848fbvh7JPs"
      },
      "id": "7848fbvh7JPs"
    },
    {
      "cell_type": "code",
      "source": [
        "# Fazer o Lazepredict import a biblioteca\n",
        "\n",
        "!pip install lazypredict -q\n",
        "\n",
        "from lazypredict.Supervised import LazyClassifier\n",
        "\n"
      ],
      "metadata": {
        "id": "54-JnQw_DIlP"
      },
      "id": "54-JnQw_DIlP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
        "                                                    test_size=0.2,\n",
        "                                                    random_state=1895)\n",
        "\n",
        "\n",
        "# verbose=0 desliga os prints de progresso de cada modelo\n",
        "# ignore_warnings=True\n",
        "clf = LazyClassifier(verbose=0,\n",
        "                     ignore_warnings=True,\n",
        "                     custom_metric=None,\n",
        "                     )\n",
        "\n",
        "# O \"fit\" aqui treina e testa todos os modelos\n",
        "\n",
        "models, predictions = clf.fit(X_train, X_test, y_train, y_test)\n",
        "\n",
        "print(models)\n",
        "\n"
      ],
      "metadata": {
        "id": "YZWlXfFWDpsw"
      },
      "id": "YZWlXfFWDpsw",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}